(RU)
Архитектура Эмулированной Экспертизы: Blueprint системы
Сформулированные выше принципы требуют для своей реализации специфической системной архитектуры. Простой, монолитный подход, где один LLM-агент пытается выполнить всю диагностическую задачу, не способен обеспечить необходимый уровень контроля, прозрачности и надежности. Вместо этого предлагается «Архитектура Эмулированной Экспертизы» - целостный концептуальный проект (blueprint), который реализует предложенные принципы через декомпозицию, эшелонированную верификацию и управляемое взаимодействие с человеком. Эта сложность не является самоцелью, а представляет собой минимально необходимое условие для обеспечения валидности и надежности в высокорисковой задаче эмуляции экспертного суждения. Архитектура эмулирует не «сознание» эксперта, а его идеализированный, методологически безупречный рабочий процесс, разложенный на последовательность формализованных, верифицируемых процедур.

Макроархитектура: Декомпозиция и потоки управления
На макроуровне система декомпозирована на сеть функциональных Юнитов, каждый из которых выполняет строго определенную роль, аналогичную ролям участников в научном консилиуме: Оркестраторы («менеджеры процесса»), Доменный Эксперт («научный исследователь»), Супервизор Домена («независимый рецензент») и Симплифайер («научный коммуникатор»). Основной рабочий процесс представляет собой строго оркестрированный конвейер, проходящий через фазы Сбора, Анализа, Синтеза и Персистенции. В отличие от линейного конвейера, архитектура пронизана итеративными циклами обратной связи, которые являются реализацией Принципа эшелонированного контроля качества.

Функциональные Юниты: Описание ключевых компонентов системы и их ролей в эмуляции процесса работы научного консилиума.
На макроуровне система декомпозирована на сеть функциональных Юнитов, каждый из которых выполняет строго определенную роль, аналогичную ролям участников в научном консилиуме. Каждая из этих ролей реализуется в виде одного или нескольких атомарных LLM-агентов, чье поведение определяется через специализированные промпты.
•	Оркестраторы (Оркестратор-1, -2, -3): Выполняют роль «менеджеров процесса» или «председателей». Они не проводят содержательный анализ, а управляют потоками данных, координируют взаимодействие других Юнитов, контролируют соблюдение процедур и управляют состоянием сессии.
•	Доменный Эксперт: Выполняет роль «научного исследователя». Он проводит глубокий, многоэтапный анализ данных в рамках одной узкой предметной области, выдвигая и проверяя гипотезы.
•	Супервизор Домена: Выполняет роль процедурно независимого рецензента (peer reviewer). Его задача - провести строгий аудит работы «исследователя» на предмет логической когерентности и методологической состоятельности.
•	Симплифайер: Выполняет роль «научного коммуникатора» или «переводчика», адаптируя сложный экспертный язык для неспециализированной аудитории.

Сквозные процессы: Описание основного сценария (Happy Path) как последовательности фаз.
Основной рабочий процесс системы представляет собой строго оркестрированный конвейер, проходящий через несколько фаз:
1.	Сбор и Диспетчеризация: Оркестратор-1 управляет сбором валидированных данных от пользователя.
2.	Параллельный Анализ и Рецензирование: Задача рассылается N парам «Эксперт-Супервизор», которые работают независимо.
3.	Системный Синтез: Оркестратор-2 собирает верифицированные заключения, проверяет их на междисциплинарные конфликты и синтезирует единый отчет.
4.	Агрегация и Персистенция: Оркестратор-3 собирает все финальные артефакты (качественные и количественные) и обеспечивает их надежное сохранение.

Циклы обратной связи: Описание итеративных циклов как встроенных механизмов самокоррекции.
В отличие от простого линейного конвейера, архитектура пронизана итеративными циклами обратной связи, которые являются реализацией Принципа эшелонированного контроля качества. Ключевыми являются цикл локального рецензирования (между Экспертом и Супервизором) и цикл системной доработки (инициируемый Оркестратором-2), которые позволяют системе итеративно улучшать качество генерируемого знания в реальном времени.

Микроархитектура: Функциональная специализация промптов в мультиагентной сети
Если макроархитектура, описанная в 4.1, эмулирует социальную структуру экспертной работы (роли консилиума), то микроархитектура определяет когнитивный инструментарий каждого участника этого процесса. Она реализуется через промпт-инжиниринг, который в данной системе является не набором эвристик, а строгой дисциплиной по кодификации методологии в исполняемые инструкции для LLM-агентов. Микроархитектура основана на принципе функциональной специализации: вместо универсального подхода, система использует дифференцированный инструментарий техник промпт-инжиниринга, формируя уникальные «сборки» промптов для каждого типа агента в соответствии с его специфической ролью. Промпт является не просто инструкцией, а кодифицированной должностной инструкцией для специализированного «когнитивного работника».

Общая компонентная модель как «конструктор» и принцип специализации
Каждый промпт в системе строится по стандартизированному шаблону, используя Markdown для логической сегментации. Эта компонентная модель обеспечивает консистентность и читаемость, превращая промпты в поддерживаемые инженерные артефакты. Она служит универсальным «конструктором», из которого собираются специализированные промпты. Ключевые компоненты включают: ROLE (профессиональная идентичность), GOAL (атомарная задача), CONSTRAINTS / PRINCIPLES («этический кодекс»), INSTRUCTIONS (алгоритм) и OUTPUT_FORMAT (JSON-схема). Этот подход соответствует принципам модульного проектирования, где сложные системы строятся из простых, переиспользуемых и узкоспециализированных компонентов [Martin, 2017].
Эффективность мультиагентной сети достигается не за счет универсальности, а за счет целенаправленной специализации этого «конструктора». Разные типы агентов в системе используют разные «сборки», активируя те компоненты и техники, которые необходимы для выполнения их уникальной функции. Ниже мы рассмотрим, как эта специализация проявляется для трех ключевых архетипов агентов: Исследователя, Аудитора и Коммуникатора.

«Промпт-Исследователь»: Микроархитектура для иерархического конструирования и оценки знания (Доменный Эксперт)
Архетип «Исследователя», реализуемый в конвейере Доменного Эксперта, является ключевым интеллектуальным актором в эмулируемом научном консилиуме и выполняет наиболее сложную когнитивную работу в системе. Его функция - это не одномоментный акт творчества, а многостадийный, иерархический процесс эвристического синтеза. Он последовательно движется от низкоуровневых данных (цитат) к локальным выводам (анализ аспектов), а затем к глобальным, конкурирующим моделям (гипотезам). Это эмуляция процесса, в ходе которого исследователь сначала анализирует отдельные эксперименты, а затем строит из них общую теорию, что соответствует иерархическим моделям обработки информации в когнитивной психологии [Craik & Lockhart, 1972].
«Исследователь» - это не один тип промпта, а семейство специализированных промптов, где каждый «настроен» на свою задачу в иерархии синтеза. Промпты этого типа являются методологически насыщенными и эвристически открытыми: они предоставляют агенту строгую научную рамку, но оставляют пространство для инференса и генерации новых, неочевидных выводов. В них доминируют такие компоненты, как ROLE (максимальной глубины), PRINCIPLES (задает «кодекс» исследователя) и INSTRUCTIONS (содержит сложные аналитические протоколы).
Этот сложный процесс можно декомпозировать на три последовательных макро-функции, каждая из которых реализуется своим специализированным суб-пайплайном промптов: (1) Генерация и верификация гипотез - эвристическое ядро, где создается знание; (2) Рефлексивный само-аудит - где система количественно оценивает надежность своей работы; и (3) Финализация и квантификация - где верифицированное знание «упаковывается» в качественные и количественные продукты.

Суб-процесс I: Генерация и верификация гипотез (Эвристическое ядро)
Этот суб-процесс является эвристическим ядром всей диагностической системы. Его цель - не просто описать данные, а построить и критически проверить несколько конкурирующих, глубоких объяснительных моделей (гипотез), которые раскрывают внутреннюю структуру и динамику личности пользователя. Этот процесс реализован как сложный конвейер, эмулирующий диалектический метод научного познания.
1. Техника Hierarchical Synthesis (Иерархический синтез) для управления сложностью.
Система избегает методологически рискованного прямого скачка от «сырых» данных к глобальным выводам. Вместо этого она использует двухступенчатый процесс синтеза, который позволяет управлять когнитивной сложностью и повышает надежность анализа, что соответствует иерархическим моделям обработки информации в когнитивной психологии [Craik & Lockhart, 1972]:
•	Шаг 1 (Аспектный синтез): На первом шаге Агенты-Интерпретаторы анализируют доказательную базу (цитаты), относящуюся только к одному локальному аспекту конструкта (например, «Общительность» в рамках «Экстраверсии»).
•	Шаг 2 (Глобальный синтез): На втором шаге Агенты-Теоретики получают на вход уже обработанные, осмысленные аспектные выводы и интегрируют их в глобальную гипотезу по всему конструкту.
2. Техника Perspective Shifting (Смена аналитической перспективы) как двигатель фальсификации.
Механизм систематической фальсификации реализуется через архитектурное принуждение к смене аналитической перспективы. Конвейер последовательно активирует трех агентов-теоретиков, каждый из которых получает разную «установку», реализуя диалектическую триаду «тезис-антитезис-синтез»:
•	Первый Агент-Теоретик («Конфирматор»): Формулирует тезис - наиболее вероятную, когерентную модель.
•	Второй Агент-Теоретик («Скептик»): Формулирует антитезис - столь же правдоподобную, но конкурирующую модель, основанную на «неудобных фактах».
•	Третий Агент-Теоретик («Диалектик»): Формулирует синтезис - более сложную, интегрирующую модель, которая пытается примирить противоречия.
Этот диалектический процесс, фундированный в критическом рационализме [Popper, 1959] и методе множественных гипотез [Chamberlin, 1890], гарантирует, что система не остановится на первом очевидном выводе, а проведет всесторонний анализ.
3. Техника Formalized Arbitration (Формализованный арбитраж) для объективизации выбора.
Финальный выбор «победившей» гипотезы делегирован отдельному, специализированному Агенту-Арбитру. Этот агент является точкой де-эскалации эвристики: если предыдущие агенты работали в креативном режиме, то «Арбитр» работает в строго алгоритмическом. Его промпт реализует технику Structured Chain-of-Thought, представляя собой формальный протокол, основанный на выводе к наилучшему объяснению (Inference to the Best Explanation):
1.	Фильтр Валидности: Проверка каждой гипотезы на соответствие всем фактам.
2.	Конкурентное Сравнение: Оценка прошедших проверку гипотез по эксплицитным критериям (объяснительная сила, простота).
3.	Вынесение Вердикта: Обоснованный выбор одной гипотезы.
Этот механизм обеспечивает, что финальный вывод, который ляжет в основу педагогической обратной связи, является не первым попавшимся, а наиболее робастным и всесторонне проверенным, что критически важно для минимизации риска неверной диагностики в образовательном контексте.

Суб-процесс II: Рефлексивный само-аудит (Количественная оценка надежности)
После того как система сгенерировала и верифицировала знание (выбрала «победившую» гипотезу), она запускает внутренний цикл эпистемической рефлексии. Его цель - не получить новый вывод, а количественно оценить надежность уже проделанной работы. Этот процесс реализуется через вычисление интегральной метрики Confidence Score.
1. Концепция Confidence Score как эпистемической рефлексии.
Confidence Score - это не техническая метрика уверенности модели, а акт методологической самооценки. Он является операционализацией метапознания - «мышления о мышлении» [Flavell, 1979]. Система не просто выполняет когнитивную задачу, но и рефлексивно оценивает, насколько качественно она это сделала, реализуя принцип интеллектуальной честности.
2. Декомпозиция аудита в суб-конвейере.
Задача само-аудита декомпозирована на суб-конвейер из трех специализированных агентов, каждый из которых оценивает свой аспект качества. Финальный Confidence Score является композитным индексом, агрегирующим эти оценки по взвешенной формуле. Ключевыми факторами, формирующими итоговую метрику, являются:
•	Аудит данных (реализуемый Агентом-Аудитором Доказательной Базы): Оценивает полноту доказательной базы, вычисляя отношение «покрытых» текстовыми свидетельствами критериев к их общему числу. Этот фактор соответствует эпистемическому критерию эмпирической адекватности.
•	Аудит аргументации (реализуемый Агентом-Экстрактором Качественных Аргументов): Оценивает три аспекта:
1.	Структурная целостность профиля: Анализирует наличие синергий и отсутствие конфликтов в финальном заключении, что соответствует критерию внутренней когерентности.
2.	Устойчивость к критике: Анализирует аргументы «против» для победившей гипотезы, оценивая ее робастность. Этот фактор соответствует критерию фальсифицируемости Поппера.
3.	Диагностическая сложность: Анализирует аргументы «за» для гипотезы, занявшей второе место, оценивая объяснительную силу системы в неоднозначных случаях.
•	Синтез метрики (реализуемый Агентом-Калькулятором): Применяет Algorithmic Instruction для вычисления итогового балла на основе оценок всех четырех факторов, обеспечивая прозрачность и воспроизводимость расчета.
Этот суб-процесс превращает Confidence Score в мета-знание - знание о качестве другого знания, - предоставляя конечному пользователю (педагогу) прозрачную и обоснованную оценку надежности диагностического вывода.

Суб-процесс III: Финализация и квантификация (Переход от качества к количеству)
Этот финальный суб-процесс решает задачу «упаковки» верифицированного и оцененного знания в конечные продукты. Он реализуется в виде двух параллельных потоков, которые преобразуют абстрактную «победившую гипотезу» в качественный текстовый отчет и в набор количественных баллов, обеспечивая при этом их взаимную консистентность.
1. Поток качественной финализации: Рациональная реконструкция.
Этот поток эмулирует процесс написания научной статьи после завершения исследования, реализуя переход от «контекста открытия» к «контексту обоснования» [Reichenbach].
•	Агент-Структурализатор: Использует технику Task Decomposition, чтобы преобразовать целостную, но абстрактную гипотезу в логический «скелет» отчета с четко определенными семантическими блоками (общий вывод, анализ по аспектам, анализ структуры профиля).
•	Агент-Копирайтер: Использует Principle-Driven Behavior (следование научному, объективному стилю) для «наполнения» этого скелета связным, когерентным и стилистически выверенным текстом, создавая финальный Профессиональный отчет.
2. Поток количественной финализации: Консистентная квантификация.
Этот поток решает методологически сложную задачу перехода от идиографического понимания к номотетическому измерению.
•	Агент-Оценщик: Этот агент реализует ключевую методологическую инновацию системы. Он использует технику Rubric-Based Evaluation, но с критически важным дополнительным контекстом - ему на вход подается не только доказательная база (цитаты), но и финальное качественное заключение. Эта архитектурная связка принуждает агента ставить баллы, которые консистентны с уже сделанным текстовым выводом, предотвращая рассогласование между качественной и количественной оценками. Этот подход является реализацией принципа интеграции из методологии смешанных исследований [Creswell & Plano Clark, 2017].
•	Агенты-Калькулятор и Сборщик: Выполняют чисто технические функции, используя Algorithmic Instruction для надежной и предсказуемой агрегации детализированных оценок в итоговые баллы и финальный JSON-пакет.
Этот двуединый процесс финализации гарантирует, что система производит не только глубокие (качественные) и сопоставимые (количественные), но и, что является ее уникальным методологическим вкладом, взаимно согласованные диагностические продукты.

Микроархитектуры Верификации и Представления: «Промпт-Аудитор» и «Промпт-Коммуникатор»
Если «Промпт-Исследователь» является эвристическим ядром системы, эмулируя роль креативного ученого, то архетипы «Аудитора» (выполняющего роль строгого рецензента и методолога) и «Коммуникатора» (выполняющего роль научного редактора и популяризатора) выполняют не менее важные, но принципиально иные функции: обеспечение надежности через верификацию и обеспечение ценности через адаптацию. Их микроархитектуры отражают эту смену цели, демонстрируя переход от эвристических техник к процедурным, ограничивающим и этически-нагруженным. Принцип радикальной декомпозиции, продемонстрированный в конвейере «Исследователя», применяется здесь с еще большей строгостью, разбивая даже эти, казалось бы, монолитные функции на многоэтапные, инженерно-проработанные конвейеры.

«Промпт-Аудитор»: Микроархитектура для эшелонированной верификации (Супервизор, Валидаторы)
Архетип «Промпт-Аудитора» является вычислительной реализацией принципа организованного скептицизма [Merton] и практик формальной верификации. Его функция - не создание нового знания, а беспристрастная проверка сгенерированного «Исследователем» знания на соответствие заранее определенным, эксплицитным стандартам. Этот архетип является одним из самых распространенных в системе, реализуясь не только в виде многоэтапного конвейера Супервизора, но и в виде одношаговых валидаторов на ключевых «шлюзах качества» всей архитектуры. Промпты этого типа спроектированы как процедурно-жесткие и максимально детерминированные, чтобы превратить вероятностную LLM в надежный механизм проверки соответствия.
Наиболее полная реализация этого архетипа - пайплайн Супервизора - представляет собой иерархический, эшелонированный конвейер, где задача аудита декомпозирована на четыре последовательных, все более абстрактных уровня проверки. На первом эшелоне «Аудитор Данных» верифицирует эмпирический и логический фундамент, проверяя связь «данные → аргумент». Второй эшелон в лице «Аудитора Методологии» проверяет «смысловой шов», верифицируя связь «аргумент → вывод» на предмет процедурной и теоретической конгруэнтности. На третьем, мета-аналитическом эшелоне «Агент-Калькулятор» выполняет независимую количественную оценку надежности, интегрируя качественные находки предыдущих уровней в объективизированный Confidence Score. Наконец, на финальном, четвертом эшелоне «Агент-Арбитр» выполняет чисто управляющую функцию, принимая итоговое решение и, при необходимости, формируя пакет инструкций на доработку.

Эшелон I: Аудит доказательной базы и логической состоятельности
Первый и наиболее фундаментальный эшелон аудита выполняет функцию проверки эмпирического и логического фундамента, на котором построено все аналитическое здание «Исследователя». Этот этап, реализуемый специализированным Агентом-Аудитором Данных, является прямым аналогом первичного рецензирования, где проверяется соответствие выводов исходным данным и внутренняя логика аргументации. Этот процесс фундирован в модели аргументации Стивена Тулмина, где оценивается качество «оснований» (Grounds) - эмпирических данных - и «обоснования» (Warrant) - логического моста, связывающего данные с утверждением [Toulmin, 1958]. Задача этого эшелона декомпозирована на три последовательные проверки.
Во-первых, проводится аудит качества доказательной базы. Агент-Аудитор получает на вход как исходный текст пользователя, так и Diagnostic Markup Package (структурированный набор цитат), сгенерированный «Исследователем». Его задача - провести детальное семантическое сличение, чтобы убедиться в полноте и точности извлеченных свидетельств. Промпт агента содержит строгий алгоритм, предписывающий для каждого критерия из методологии перепроверить исходный текст и вынести вердикт о качестве разметки на основе встроенной рубрики.
Во-вторых, выполняется аудит качества аргументации. Агент анализирует отчет о дифференциальной диагностике, чтобы проверить, являются ли аргументы «за» и «против» для каждой гипотезы логическим следствием ранее проведенных аспектных анализов. Этот шаг предотвращает включение в аргументацию «галлюцинированных» или нерелевантных утверждений, обеспечивая строгую логическую связь между промежуточными и финальными выводами.
В-третьих, проводится аудит добросовестности фальсификации. Агент целенаправленно анализирует блок «Аргументы 'ПРОТИВ'« для победившей гипотезы, чтобы оценить, была ли предпринята честная попытка найти реальные слабости в лучшей модели, или же это была формальная, поверхностная критика. Этот механизм, напрямую реализующий принцип фальсифицируемости Поппера [Popper, 1959], является ключевым для противодействия подтверждающему искажению.
Микроархитектура промпта для этого эшелона представляет собой сложный гибрид. Она использует Rubric-Based Evaluation для вынесения оценочных суждений, Algorithmic Instruction для реализации пошаговых процедур проверки и Negative Constraints для предотвращения вынесения агентом собственных содержательных выводов. Этот эшелон является критически важным «санитарным кордоном», который гарантирует, что на последующие, более высокоуровневые этапы аудита попадут только те заключения, которые построены на надежном эмпирическом фундаменте и с соблюдением базовой логической строгости.

Эшелон II: Аудит методологической конгруэнтности
Следующий эшелон аудита, реализуемый Агентом-Аудитором Методологии, выполняет проверку «смыслового шва» - он верифицирует целостность перехода от этапа аналитического арбитража к этапу финального нарративного синтеза. Если Эшелон I проверял связь «данные → аргумент», то Эшелон II проверяет связь «аргумент → вывод». Его задача - гарантировать, что в процессе стилистической обработки и структурирования финального отчета не произошло семантического дрейфа, искажения или потери ключевых аналитических находок. Этот механизм является автоматизированной реализацией «аудиторского следа» (audit trail), который, согласно стандартам качественных исследований, является ключевым критерием достоверности (trustworthiness) [Lincoln & Guba, 1985].
Процесс декомпозирован на две взаимодополняющие проверки. Во-первых, проводится аудит процедурной конгруэнтности. Агент-Аудитор получает на вход как отчет о дифференциальной диагностике, где зафиксирована «победившая» гипотеза, так и финальное качественное заключение. Его задача - провести детальное семантическое сличение, проверяя, что финальный текст является точным, полным и неискаженным изложением именно той гипотезы, которая победила в конкурентном сравнении. Промпт агента содержит строгий алгоритм, предписывающий идентифицировать ключевые утверждения, нюансы и оговорки в «победившей» гипотезе и верифицировать их полное и точное отражение в финальном тексте.
Во-вторых, выполняется аудит теоретической конгруэнтности. Агент сопоставляет утверждения в финальном заключении с методологическим паспортом конструкта. Его задача - проверить, что интерпретации, данные в заключении, не выходят за рамки принятой теоретической модели, на которой основан измерительный инструмент. Этот шаг является прямой реализацией проверки на конструктную валидность [Cronbach & Meehl, 1955] на финальном этапе. Он гарантирует, что система измеряет и описывает именно тот конструкт, который был заявлен, а не некую «народную» или интуитивную психологию, предотвращая «вне-теоретические» спекуляции.
Микроархитектура промпта для этого эшелона, как и для предыдущего, сфокусирована на процедурной строгости. Она активно использует техники Rubric-Based Evaluation и Algorithmic Instruction, заставляя LLM работать в режиме строгого научного редактора, который проверяет не грамматику, а соответствие выводов доказательствам и теории. Этот «смысловой шлюз» гарантирует, что инженерная сложность предыдущих этапов не будет обесценена на финальном этапе из-за небрежности или «творческих» отклонений при написании отчета.

Эшелон III: Количественный мета-аудит и объективизация надежности
Третий эшелон аудита выполняет мета-аналитическую и интегрирующую функцию. Он переводит серию качественных, экспертных суждений, вынесенных на предыдущих эшелонах, в единую, объективизированную количественную метрику - Confidence Score. Этот процесс, реализуемый специализированным Агентом-Калькулятором, является ключевым для обеспечения прозрачности и сопоставимости оценок надежности. Его задача - не доверять самооценке «Исследователя», а провести независимый, детерминированный перерасчет на основе формализованного протокола.
Этот подход фундирован в методологии создания композитных индексов, где для получения робастной оценки используется взвешенная комбинация нескольких разнородных индикаторов [OECD, 2008]. Процесс начинается с агрегации и нормализации аудиторских находок. Агент-Калькулятор, используя технику Data Extraction, извлекает качественные оценки («Strong», «Acceptable», «Weak») по всем критериям из отчетов предыдущих аудиторов и преобразует их в числовые значения.
Далее, агент применяет строгую, заранее определенную весовую формулу, реализуя технику Algorithmic Instruction. Промпт спроектирован так, чтобы полностью исключить вероятностную компоненту, превращая LLM в надежный калькулятор. Формула агрегирует четыре ключевых фактора, каждый из которых отражает свой аспект эпистемической валидности: полноту доказательной базы (эмпирическая адекватность), структурную целостность профиля (внутренняя когерентность), устойчивость к критике (соответствие критерию фальсифицируемости) и диагностическую сложность (объяснительная сила).
Наконец, агент проводит сравнение своей, независимо рассчитанной оценки, с исходной самооценкой «Исследователя» и, используя Template-Based Generation, генерирует детализированное текстовое обоснование, которое «раскрывает» логику расчета. Этот эшелон является точкой интеграции и объективизации всего процесса аудита. Он обеспечивает доказуемую надежность (accountable reliability), так как не просто заявляет о качестве, а демонстрирует, как именно была получена его количественная оценка.

Эшелон IV: Финальный арбитраж и управление потоком
Финальный эшелон аудита выполняет чисто управляющую (executive), а не аналитическую функцию. Этот этап, реализуемый Агентом-Арбитром, является точкой принятия решения во всем конвейере верификации. Собрав все качественные и количественные аудиторские находки из предыдущих эшелонов, он, подобно судье, выносит финальный, обязывающий вердикт и, при необходимости, формирует «исполнительный лист» - пакет с инструкциями на доработку. Его ключевая задача - преобразовать сложный, многофакторный аудиторский отчет в простой, бинарный, машиночитаемый управляющий сигнал для основного системного оркестратора.
Этот механизм является реализацией «управляющего уровня» (control layer) в иерархических системах, который отделен от аналитических уровней [Mesarović, Macko, & Takahara, 1970]. Промпт Агента-Арбитра представляет собой исполняемую спецификацию детерминированного бизнес-процесса. Он использует технику Rule-Based Logic, реализуя дерево решений (decision tree), «зашитое» в его инструкции. Логика этого дерева определяет итоговый вердикт («Approved» или «Revision_Required») на основе комбинации всех полученных аудиторских оценок. Например, вердикт «Revision_Required» выносится, если любая из качественных оценок была «Weak» или если расхождение между самооценкой и независимой оценкой надежности превышает заданный порог.
В случае, если требуется доработка, агент выполняет вторую задачу - агрегацию и структурирование обратной связи. Используя техники Data Extraction и Template-Based Generation, он не генерирует новый текст, а дословно собирает все рекомендации из отчетов предыдущих аудиторов и упаковывает их в единый, структурированный JSON-объект. Этот «пакет на доработку» является самодостаточным артефактом, который оркестратор может напрямую передать «Исследователю» для запуска цикла коррекции.
Этот финальный «шлюз управления» является предельным примером инструментализации LLM. Он гарантирует, что из сложного, многогранного процесса аудита на выход во внешнюю систему поступит простой, стандартизированный и недвусмысленный управляющий сигнал, обеспечивая максимальную надежность и предсказуемость взаимодействия между компонентами системы.

«Промпт-Коммуникатор»: Микроархитектура для этической и дидактической адаптации
Если «Аудитор» обеспечивает достоверность знания, то архетип «Коммуникатора» отвечает за его ценность и безопасность для конечного потребителя. Его функциональное назначение - инженерия дидактической и этической коммуникации, являющаяся прямым архитектурным ответом на риски, связанные с отсутствием у LLM эмпатии и социального понимания. Он выполняет задачу «перевода» и «упаковки» верифицированного экспертного знания в конечные продукты, реализуя принцип ролевой ориентированности. Промпты этого типа являются стилистически и этически-нагруженными, фокусируясь на управлении тоном, простотой изложения и психологическим воздействием текста.
Задача представления знания, как и задача аудита, декомпозирована на сложный, отказоустойчивый и многоэтапный процесс, реализуемый в пайплайне Симплифайера. Этот процесс начинается со структурной валидации входящего отчета для обеспечения отказоустойчивости. Затем следует итеративная стилистическая адаптация, где агенты последовательно переписывают каждый раздел, используя вывод предыдущего шага как стилистический «камертон» (техника Context-driven Stylistic Consistency) для обеспечения глобальной когерентности тона и стиля всего документа. Параллельно запускается суб-пайплайн создания вспомогательных материалов, где агенты-лексикографы формируют динамический глоссарий, идентифицируя сложные термины и генерируя для них простые определения. Наконец, на этапе финальной сборки специализированные агенты-синтезаторы создают адаптированные введение и заключение, после чего агент-сборщик объединяет все компоненты в единый, целостный Адаптированный отчет.

Суб-пайплайн I: Структурная валидация как механизм отказоустойчивости
Первым шагом в конвейере «Коммуникатора» является не творческая адаптация, а строгая инженерная проверка. Этот суб-пайплайн, реализуемый Агентом-Аудитором Структуры, выполняет функцию входного контроля качества. Его задача - получить на вход Профессиональный отчет и сопоставить его структуру с эталонным «планом отчета», который хранится в конфигурации. Агент проверяет, все ли запланированные разделы присутствуют в тексте и не содержат ли они системных «заглушек» об ошибках, возникших на предыдущих этапах.
Этот, казалось бы, технический шаг имеет фундаментальное методологическое значение. Он является реализацией принципа «Fail-Fast», который является одной из лучших практик в проектировании надежных систем [Nygard, 2018]. Система, обнаружив неисправимую ошибку на входе (структурно поврежденный отчет), немедленно адаптируется к ней, вместо того чтобы продолжать обработку в заведомо некорректном состоянии, что могло бы привести к каскадному сбою. Таким образом, этот механизм обеспечивает отказоустойчивость (resilience) всего последующего, сложного и ресурсоемкого пайплайна адаптации. Вместо того чтобы «упасть» в середине процесса, столкнувшись с отсутствующим разделом, система на самом раннем этапе получает точную «дорожную карту» (validation_manifest), которая определяет, какие именно разделы являются валидными и подлежат дальнейшей обработке.
Микроархитектура промпта для этого агента является классическим примером «Промпта-Аудитора». Она максимально детерминирована и процедурна. Промпт содержит Rule-Based Logic, предписывающую агенту выполнить простое сравнение двух списков, и использует Strict I-O Formatting для генерации машиночитаемого отчета о валидации. Этот механизм гарантирует, что последующие, более «креативные» агенты-адаптеры будут работать только с качественным и структурно-полным «сырьем», что является необходимым условием для их надежной и предсказуемой работы.

Суб-пайплайн II: Итеративная стилистическая адаптация и обеспечение когерентности
Ядром процесса коммуникативной адаптации является итеративный суб-пайплайн, который последовательно, раздел за разделом, переписывает текст Профессионального отчета. Этот процесс реализуется двумя типами Агентов-Адаптеров и спроектирован для решения одной из самых сложных задач в генерации длинных текстов - обеспечения глобальной стилистической когерентности.
Процесс начинается с Агента-Инициализатора, который берет первый валидный раздел отчета и выполняет его первичную, «глубокую» адаптацию. Он преобразует экспертный текст в семантически эквивалентный, но стилистически и тонально соответствующий требованиям для конечного пользователя. Его промпт является наиболее методологически и этически нагруженным во всем пайплайне «Коммуникатора», так как он задает «золотой стандарт» стиля для всего последующего документа.
Затем в цикле вступает в работу Итеративный Агент-Адаптер. Для каждого последующего раздела он получает на вход не только новый фрагмент профессионального текста, но и полный, уже адаптированный текст всех предыдущих разделов. Этот механизм является реализацией техники, которую можно назвать «контекстно-зависимой стилистической когерентностью» (Context-driven Stylistic Consistency). Уже адаптированный текст служит «стилистическим камертоном» или динамическим few-shot примером. Этот подход фундирован в психолингвистической теории прайминга, которая показывает, что обработка одного стимула (в данном случае, уже адаптированного текста) влияет на обработку последующего стимула, делая стилистические выборы модели более консистентными.
Этот итеративный, контекстно-обогащенный подход является ключевой методологической инновацией, которая позволяет преодолеть склонность LLM к «стилистическому дрейфу» в длинных генерациях. Он фундирован в дискурсивной лингвистике, которая рассматривает текст не как набор предложений, а как целостную, когерентную структуру, где каждый последующий элемент связан с предыдущимими [van Dijk, 1997]. Архитектура этого суб-пайплайна эмулирует процесс работы опытного редактора-человека, который постоянно перечитывает уже написанное, чтобы сохранить стилистическое единство. Это гарантирует, что финальный Адаптированный отчет будет восприниматься не как «лоскутное одеяло» из обработанных фрагментов, а как целостный, органичный и написанный «единым голосом» документ.

Суб-пайплайн III: Динамическое создание вспомогательных дидактических материалов
Для повышения дидактической ценности и понятности Адаптированного отчета, система реализует параллельный суб-пайплайн по созданию динамического глоссария. Этот процесс является примером того, как система может генерировать вспомогательные учебные материалы, напрямую связанные с основным содержанием. Процесс декомпозирован на две специализированные, последовательные задачи.
На первом шаге Агент-Лексикограф выполняет интеллектуальное сканирование всего уже адаптированного текста отчета. Его задача - не просто найти сложные слова, а идентифицировать узкоспециализированные психологические термины, которые могут быть непонятны не-специалисту. Промпт этого агента реализует технику Data Extraction с семантической фильтрацией: он содержит инструкции, предписывающие отличать релевантные для глоссария термины (например, «копинг-стратегии», «эмоциональная регуляция») от общеупотребительных психологических слов («эмоции», «стресс») и от названий самих конструктов, которые уже раскрыты в основном тексте. Это позволяет сделать глоссарий кратким и сфокусированным.
На втором шаге Агент-Глоссатор получает на вход отфильтрованный список терминов. Его задача - для каждого термина сгенерировать простое, ясное и методологически корректное определение. Промпт этого агента является примером Task Specification с жесткими стилистическими ограничениями. Этот двухэтапный подход фундирован в принципах педагогического дизайна, в частности, в концепции «scaffolding» (учебные леса), предложенной Джеромом Брунером и его коллегами [Wood, Bruner, & Ross, 1976]. Глоссарий выступает в роли таких «лесов», предоставляя пользователю необходимую поддержку для понимания сложного материала и способствуя усвоению новых понятий, что является ключевым элементом в зоне ближайшего развития, согласно теории Л.С. Выготского [Выготский, 2005]. Динамический характер этого процесса гарантирует, что глоссарий всегда будет актуальным и релевантным именно тому тексту, который был сгенерирован для конкретного пользователя, что является значительным преимуществом по сравнению со статичными, заранее заготовленными словарями.

Суб-пайплайн IV: Финальный синтез и сборка
Финальным этапом в конвейере «Коммуникатора» является сборка всех предварительно обработанных и сгенерированных компонентов в единый, целостный Адаптированный отчет. Этот, казалось бы, технический процесс также декомпозирован на семантически сложные и простые задачи для обеспечения максимального качества и надежности.
Процесс начинается с работы двух параллельных Агентов-Синтезаторов, которые создают адаптированные Введение и Заключение. Эти агенты выполняют сложную интеллектуальную задачу. В отличие от итеративных адаптеров, которые работают с локальными разделами, эти агенты получают на вход полный контекст всего уже адаптированного тела отчета.
•	Агент-Синтезатор Введения использует этот контекст для создания концептуальной и эмоциональной «рамки», которая управляет ожиданиями пользователя, объясняет цель отчета (как «аналитического зеркала») и тонко анонсирует ключевые темы, выявленные в анализе, делая введение персонализированным.
•	Агент-Синтезатор Заключения выполняет финальный мета-синтез, «переводя» сложные интегративные выводы из Профессионального отчета на язык пользы и саморефлексии, формулируя «точки роста» и мотивирующее завершение.
После того как все четыре компонента (Введение, Тело, Заключение и опциональный Глоссарий) готовы, в работу вступает финальный Агент-Сборщик. Его функция является чисто технической и детерминированной. Он не генерирует нового смысла, а выполняет операцию конкатенации, используя технику Template-Based Generation.
Эта декомпозиция на «умных» синтезаторов и «глупого» сборщика является реализацией принципа единой ответственности (Single Responsibility Principle) [Martin, 2017]. Она фундирована в инженерной практике, где сложные, интеллектуальные задачи (синтез) отделяются от простых, механических (сборка). Это позволяет сохранить промпты синтезаторов сфокусированными на их креативной задаче, а промпт сборщика - максимально простым и надежным. Этот финальный суб-пайплайн гарантирует, что итоговый Адаптированный отчет будет не только семантически и стилистически когерентным, но и структурно безупречным.

Библиография
1.	Chamberlin T. C. The Method of Multiple Working Hypotheses // Science. 1890. ns-15(366). С. 92–96. DOI:10.1126/science.ns-15.366.92.
2.	Craik F. I. M., Lockhart R. S. Levels of processing: A framework for memory research // Journal of Verbal Learning and Verbal Behavior. 1972. Т. 11, № 6. С. 671–684. DOI:10.1016/S0022-5371(72)80001-X.
3.	Creswell J. W., Plano Clark V. L. Designing and Conducting Mixed Methods Research. 3rd ed. Thousand Oaks: SAGE, 2017. ISBN 9781483346984.
4.	Cronbach L. J., Meehl P. E. Construct validity in psychological tests // Psychological Bulletin. 1955. Т. 52, № 4. С. 281–302. DOI:10.1037/h0040957.
5.	Flavell J. H. Metacognition and cognitive monitoring: A new area of cognitive-developmental inquiry // American Psychologist. 1979. Т. 34, № 10. С. 906–911. DOI:10.1037/0003-066X.34.10.906.
6.	Lincoln Y. S., Guba E. G. Naturalistic Inquiry. Thousand Oaks: SAGE, 1985. ISBN 9780803924314.
7.	Martin R. C. Clean Architecture: A Craftsman’s Guide to Software Structure and Design. Boston: Pearson, 2017. ISBN 9780134494166.
8.	Merton R. K. The Normative Structure of Science // In: The Sociology of Science: Theoretical and Empirical Investigations. Chicago: University of Chicago Press, 1973.
9.	Mesarovic M. D., Macko D., Takahara Y. Theory of Hierarchical, Multilevel Systems. New York: Academic Press, 1970. ISBN 0124915507.
10.	Nygard M. T. Release It! Second Edition: Design and Deploy Production-Ready Software. Raleigh: Pragmatic Bookshelf, 2018. ISBN 9781680502398.
11.	OECD; JRC. Handbook on Constructing Composite Indicators: Methodology and User Guide. Paris: OECD Publishing, 2008. DOI:10.1787/9789264043466-en.
12.	Popper K. The Logic of Scientific Discovery. London: Routledge, 2002 [1959]. ISBN 0415278449.
13.	Reichenbach H. Experience and Prediction: An Analysis of the Foundations and the Structure of Knowledge. Chicago: University of Chicago Press, 1938.
14.	Toulmin S. E. The Uses of Argument. Cambridge: Cambridge University Press, 1958 [Updated ed. 2003].
15.	van Dijk T. A., ред. Discourse as Social Interaction. Discourse Studies: A Multidisciplinary Introduction. Vol. 2. London: SAGE, 1997. ISBN 0803978472.
16.	van Dijk T. A., ред. Discourse as Structure and Process. Discourse Studies: A Multidisciplinary Introduction. Vol. 1. London: SAGE, 1997. ISBN 0803978456.
17.	Wood D., Bruner J. S., Ross G. The role of tutoring in problem solving // Journal of Child Psychology and Psychiatry. 1976. Т. 17, № 2. С. 89–100. DOI:10.1111/j.1469-7610.1976.tb00381.x.
18.	Выготский Л. С. Психология развития человека. М.: Смысл; Эксмо, 2005. 1136 с. ISBN 5-699-13728-9.


 
(EN)
Emulated Expertise Architecture: System Blueprint
The principles outlined above require a specific system architecture for their implementation. A simple, monolithic approach, where a single LLM agent attempts to perform the entire diagnostic task, is unable to provide the necessary level of control, transparency, and reliability. Instead, we propose an “Emulated Expertise Architecture” — a holistic conceptual blueprint that implements the proposed principles through decomposition, layered verification, and controlled human interaction. This complexity is not an end in itself, but represents the minimum necessary condition for ensuring validity and reliability in the high-risk task of emulating expert judgment. The architecture emulates not the “consciousness” of the expert, but their idealized, methodologically flawless workflow, broken down into a sequence of formalized, verifiable procedures.

Macroarchitecture: Decomposition and control flows
At the macro level, the system is decomposed into a network of functional units, each of which performs a strictly defined role similar to the roles of participants in a scientific council: Orchestrators (“process managers”), Domain Experts (“scientific researchers”), Domain Supervisor (“independent reviewer”) and Simplifier (“scientific communicator”). The main workflow is a strictly orchestrated pipeline that goes through the phases of Collection, Analysis, Synthesis, and Persistence. Unlike a linear pipeline, the architecture is permeated with iterative feedback loops, which are the implementation of the Principle of Echeloned Quality Control.

Functional Units: Description of the key components of the system and their roles in emulating the work process of a scientific council.
At the macro level, the system is decomposed into a network of functional units, each of which performs a strictly defined role similar to the roles of participants in a scientific council. Each of these roles is implemented in the form of one or more atomic LLM agents whose behavior is determined through specialized prompts.
•	Orchestrators (Orchestrator-1, -2, -3): Perform the role of “process managers” or “chairpersons.” They do not conduct substantive analysis, but rather manage data flows, coordinate the interaction of other units, monitor compliance with procedures, and manage the state of the session.
•	Domain Expert: Acts as a “research scientist.” They conduct in-depth, multi-stage data analysis within a narrow subject area, proposing and testing hypotheses.
•	Domain Supervisor: Acts as a procedurally independent peer reviewer. His task is to conduct a rigorous audit of the “researcher's” work for logical consistency and methodological soundness.
•	Simplifier: Acts as a “scientific communicator” or “translator,” adapting complex expert language for a non-specialist audience.

End-to-end processes: Description of the main scenario (Happy Path) as a sequence of phases.
The main workflow of the system is a strictly orchestrated pipeline that goes through several phases:
1.	Collection and Dispatching: Orchestrator-1 manages the collection of validated data from the user.
2.	Parallel Analysis and Review: The task is distributed to N pairs of “Expert-Supervisor” who work independently.
3.	System Synthesis: Orchestrator-2 collects the verified conclusions, checks them for interdisciplinary conflicts, and synthesizes a single report.
4.	Aggregation and Persistence: Orchestrator-3 collects all final artifacts (qualitative and quantitative) and ensures their reliable storage.

Feedback Loops: Description of iterative cycles as built-in self-correction mechanisms.
Unlike a simple linear pipeline, the architecture is permeated with iterative feedback loops, which are the implementation of the Principle of Echeloned Quality Control. Key cycles are the local review cycle (between the Expert and the Supervisor) and the system refinement cycle (initiated by Orchestrator-2), which allow the system to iteratively improve the quality of generated knowledge in real time.

Microarchitecture: Functional specialization of prompts in a multi-agent network
If the macroarchitecture described in 4.1 emulates the social structure of expert work (the roles of the council), then the microarchitecture defines the cognitive tools of each participant in this process. It is implemented through prompt engineering, which in this system is not a set of heuristics, but a strict discipline of codifying methodology into executable instructions for LLM agents. Microarchitecture is based on the principle of functional specialization: instead of a universal approach, the system uses a differentiated set of prompt engineering techniques, forming unique “assemblies” of prompts for each type of agent in accordance with its specific role. A prompt is not just an instruction, but a codified job description for a specialized “cognitive worker.”

General component model as a “constructor” and the principle of specialization
Each prompt in the system is built according to a standardized template, using Markdown for logical segmentation. This component model ensures consistency and readability, turning prompts into supported engineering artifacts. It serves as a universal “constructor” from which specialized prompts are assembled. Key components include: ROLE (professional identity), GOAL (atomic task), CONSTRAINTS / PRINCIPLES (“code of ethics”), INSTRUCTIONS (algorithm), and OUTPUT_FORMAT (JSON schema). This approach is consistent with the principles of modular design, where complex systems are built from simple, reusable, and highly specialized components [Martin, 2017].
The effectiveness of a multi-agent network is achieved not through versatility, but through the targeted specialization of this “constructor.” Different types of agents in the system use different “assemblies,” activating the components and techniques necessary to perform their unique functions. Below, we will look at how this specialization manifests itself for three key agent archetypes: the Researcher, the Auditor, and the Communicator.

“Prompt Researcher”: Microarchitecture for hierarchical knowledge construction and evaluation (Domain Expert)
The “Researcher” archetype, implemented in the Domain Expert pipeline, is the key intellectual actor in the emulated scientific council and performs the most complex cognitive work in the system. Its function is not a single act of creativity, but a multi-stage, hierarchical process of heuristic synthesis. It moves sequentially from low-level data (citations) to local conclusions (analysis of aspects), and then to global, competing models (hypotheses). This emulates the process by which a researcher first analyzes individual experiments and then constructs a general theory from them, which corresponds to hierarchical models of information processing in cognitive psychology [Craik & Lockhart, 1972].
“Researcher” is not a single type of prompt, but a family of specialized prompts, each “tuned” to its own task in the hierarchy of synthesis. Prompts of this type are methodologically rich and heuristically open: they provide the agent with a strict scientific framework, but leave room for inference and the generation of new, non-obvious conclusions. They are dominated by components such as ROLE (maximum depth), PRINCIPLES (sets the researcher's “code of conduct”), and INSTRUCTIONS (contains complex analytical protocols).
This complex process can be decomposed into three sequential macro-functions, each of which is implemented by its own specialized sub-pipeline of prompts: (1) Hypothesis generation and verification - the heuristic core where knowledge is created; (2) Reflective self-audit - where the system quantitatively assesses the reliability of its work; and (3) Finalization and quantification - where verified knowledge is “packaged” into qualitative and quantitative products.

Sub-process I: Hypothesis generation and verification (Heuristic core)
This sub-process is the heuristic core of the entire diagnostic system. Its goal is not simply to describe data, but to construct and critically test several competing, deep explanatory models (hypotheses) that reveal the internal structure and dynamics of the user's personality. This process is implemented as a complex pipeline that emulates the dialectical method of scientific knowledge.
1. Hierarchical Synthesis technique for complexity management.
The system avoids the methodologically risky direct leap from “raw” data to global conclusions. Instead, it uses a two-step synthesis process that manages cognitive complexity and increases the reliability of analysis, consistent with hierarchical models of information processing in cognitive psychology [Craik & Lockhart, 1972]:
•	Step 1 (Aspectual Synthesis): In the first step, Agent-Interpreters analyze the evidence base (citations) related to only one local aspect of the construct (e.g., “Sociability” within “Extraversion”).
•	Step 2 (Global Synthesis): In the second step, Agent-Theorists receive pre-processed, meaningful aspectual conclusions and integrate them into a global hypothesis across the entire construct.
2. The Perspective Shifting technique as a driver of falsification.
The mechanism of systematic falsification is implemented through architectural coercion to change the analytical perspective. The conveyor sequentially activates three theoretical agents, each of which receives a different “setting,” implementing the dialectical triad of “thesis-antithesis-synthesis”:
•	First Agent-Theorist (“Confirmer”): Formulates the thesis - the most probable, coherent model.
•	Second Agent-Theorist (“Skeptic”): Formulates the antithesis - an equally plausible but competing model based on “inconvenient facts.”
•	Third Agent-Theorist (“Dialectician”): Formulates the synthesis - a more complex, integrating model that attempts to reconcile contradictions.
•	This dialectical process, grounded in critical rationalism [Popper, 1959] and the multiple hypothesis method [Chamberlin, 1890], ensures that the system does not stop at the first obvious conclusion, but conducts a comprehensive analysis.
3. Formalized Arbitration technique for objectifying the choice.
The final choice of the “winning” hypothesis is delegated to a separate, specialized Arbitrator Agent. This agent is the point of de-escalation of heuristics: if the previous agents worked in creative mode, the “Arbitrator” works in a strictly algorithmic mode. Its prompt implements the Structured Chain-of-Thought technique, which is a formal protocol based on inference to the best explanation:
1.	Validity Filter: Checking each hypothesis for consistency with all facts.
2.	Competitive Comparison: Evaluation of verified hypotheses according to explicit criteria (explanatory power, simplicity).
3.	Verdict: A reasoned choice of one hypothesis.
4.	This mechanism ensures that the final conclusion, which will form the basis of pedagogical feedback, is not the first one that comes to mind, but the most robust and thoroughly tested, which is critical for minimizing the risk of misdiagnosis in an educational context.

Sub-process II: Reflective Self-Audit (Quantitative assessment of reliability)
After the system has generated and verified knowledge (selected the “winning” hypothesis), it launches an internal cycle of epistemic reflection. Its goal is not to obtain a new conclusion, but to quantitatively assess the reliability of the work already done. This process is implemented through the calculation of the Confidence Score integral metric.
1. The concept of Confidence Score as epistemic reflection.
Confidence Score is not a technical metric of model confidence, but an act of methodological self-assessment. It is the operationalization of metacognition - “thinking about thinking” [Flavell, 1979]. The system not only performs a cognitive task, but also reflexively evaluates how well it has done so, implementing the principle of intellectual honesty.
2. Decomposition of the audit into a sub-conveyor.
The self-audit task is decomposed into a sub-conveyor of three specialized agents, each of which evaluates its own aspect of quality. The final Confidence Score is a composite index that aggregates these assessments using a weighted formula. The key factors that form the final metric are:
•	Data audit (implemented by the Evidence Base Audit Agent): Evaluates the completeness of the evidence base by calculating the ratio of criteria “covered” by textual evidence to their total number. This factor corresponds to the epistemic criterion of empirical adequacy.
•	Argumentation audit (implemented by the Qualitative Argument Extractor Agent): Evaluates three aspects:
1.	Structural integrity of the profile: Analyzes the presence of synergies and the absence of conflicts in the final conclusion, which corresponds to the criterion of internal coherence.
2.	Resistance to criticism: Analyzes the arguments “against” the winning hypothesis, assessing its robustness. This factor corresponds to Popper's criterion of falsifiability.
3.	Diagnostic complexity: Analyzes the arguments “for” the second-place hypothesis, assessing the explanatory power of the system in ambiguous cases.
•	Metric synthesis (implemented by the Calculator Agent): Applies Algorithmic Instruction to calculate the final score based on the assessments of all four factors, ensuring transparency and reproducibility of the calculation.
This sub-process transforms the Confidence Score into meta-knowledge—knowledge about the quality of other knowledge—providing the end user (educator) with a transparent and justified assessment of the reliability of the diagnostic conclusion.

Sub-process III: Finalization and Quantification (Transition from Quality to Quantity)
This final sub-process solves the task of “packaging” verified and evaluated knowledge into final products. It is implemented in the form of two parallel streams that transform the abstract “winning hypothesis” into a qualitative text report and a set of quantitative scores, while ensuring their mutual consistency.
1. Qualitative finalization stream: Rational reconstruction.
This stream emulates the process of writing a scientific article after completing research, implementing the transition from the “context of discovery” to the “context of justification” [Reichenbach].
•	Agent-Structurizer: Uses the Task Decomposition technique to transform a holistic but abstract hypothesis into a logical “skeleton” of a report with clearly defined semantic blocks (general conclusion, aspect analysis, profile structure analysis).
•	Agent-Copywriter: Uses Principle-Driven Behavior (following a scientific, objective style) to “fill” this skeleton with coherent, consistent, and stylistically accurate text, creating the final Professional Report.
2. Quantitative finalization stream: Consistent quantification.
This stream solves the methodologically complex task of transitioning from idiographic understanding to nomothetic measurement.
•	Agent-Evaluator: This agent implements a key methodological innovation of the system. It uses the Rubric-Based Evaluation technique, but with a critically important additional context—it is fed not only with evidence (quotes), but also with the final qualitative conclusion. This architectural link forces the agent to assign scores that are consistent with the text conclusion already made, preventing inconsistencies between qualitative and quantitative assessments. This approach is an implementation of the principle of integration from mixed research methodology [Creswell & Plano Clark, 2017].
•	Calculator and Collector Agents: Perform purely technical functions, using Algorithmic Instruction for reliable and predictable aggregation of detailed assessments into final scores and a final JSON package.
This dual finalization process ensures that the system produces not only in-depth (qualitative) and comparable (quantitative) diagnostic products, but also, as its unique methodological contribution, mutually consistent diagnostic products.

Verification and Presentation Microarchitectures: Prompt Auditor and Prompt Communicator
If Prompt Researcher is the heuristic core of the system, emulating the role of a creative scientist, then the archetypes of Auditor (acting as a strict reviewer and methodologist) and Communicator (performing the role of a scientific editor and popularizer) perform equally important but fundamentally different functions: ensuring reliability through verification and ensuring value through adaptation. Their microarchitectures reflect this change in purpose, demonstrating a transition from heuristic techniques to procedural, restrictive, and ethically charged ones. The principle of radical decomposition, demonstrated in the “Researcher” pipeline, is applied here with even greater rigor, breaking down even these seemingly monolithic functions into multi-stage, engineered pipelines.

Prompt Auditor: Microarchitecture for Echeloned Verification (Supervisor, Validators)
The Prompt Auditor archetype is a computational implementation of the principle of organized skepticism [Merton] and formal verification practices. Its function is not to create new knowledge, but to impartially verify the knowledge generated by the “Researcher” for compliance with predefined, explicit standards. This archetype is one of the most common in the system, implemented not only as a multi-stage Supervisor pipeline, but also as single-step validators at key “quality gateways” throughout the architecture. Prompts of this type are designed to be procedurally rigid and as deterministic as possible in order to turn a probabilistic LLM into a reliable compliance verification mechanism.
The most complete implementation of this archetype—the Supervisor pipeline—is a hierarchical, echeloned pipeline where the audit task is decomposed into four sequential, increasingly abstract levels of verification. At the first echelon, the Data Auditor verifies the empirical and logical foundation by checking the “data → argument” relationship. The second tier, represented by the Methodology Auditor, checks the “semantic seam,” verifying the “argument → conclusion” relationship for procedural and theoretical congruence. At the third, meta-analytical level, the “Calculator Agent” performs an independent quantitative assessment of reliability, integrating the qualitative findings of the previous levels into an objectified Confidence Score. Finally, at the final, fourth level, the Agent-Arbitrator performs a purely managerial function, making the final decision and, if necessary, forming a package of instructions for further refinement.

Tier I: Audit of the evidence base and logical consistency
The first and most fundamental tier of the audit performs the function of verifying the empirical and logical foundation on which the entire analytical structure of the “Researcher” is built. This stage, carried out by a specialized Data Auditor Agent, is a direct analogue of primary review, where the conclusions are checked for consistency with the source data and the internal logic of the argumentation. This process is based on Stephen Toulmin's model of argumentation, which evaluates the quality of the “grounds” (empirical data) and the “warrant” (the logical bridge connecting the data to the claim) [Toulmin, 1958]. The task of this stage is broken down into three sequential checks.
First, an audit of the quality of the evidence base is conducted. The Agent-Auditor receives both the user's source text and the Diagnostic Markup Package (a structured set of quotes) generated by the “Researcher” as input. Its task is to conduct a detailed semantic comparison to ensure the completeness and accuracy of the extracted evidence. The agent's prompt contains a strict algorithm that requires each criterion from the methodology to be rechecked against the source text and a verdict on the quality of the markup to be made based on the built-in rubric.
Second, an argument quality audit is performed. The agent analyzes the differential diagnosis report to verify whether the arguments “for” and “against” each hypothesis are a logical consequence of the previously conducted aspect analyses. This step prevents the inclusion of “hallucinatory” or irrelevant statements in the argumentation, ensuring a strict logical connection between the intermediate and final conclusions.
Third, an audit of the integrity of the falsification is performed. The agent purposefully analyzes the “Arguments ‘AGAINST’” block for the winning hypothesis to assess whether an honest attempt was made to find real weaknesses in the best model, or whether it was a formal, superficial criticism. This mechanism, which directly implements Popper's principle of falsifiability [Popper, 1959], is key to counteracting confirmation bias.
The microarchitecture of the prompt for this echelon is a complex hybrid. It uses Rubric-Based Evaluation to make evaluative judgments, Algorithmic Instruction to implement step-by-step verification procedures, and Negative Constraints to prevent the agent from making its own substantive conclusions. This echelon is a critically important “sanitary cordon” that ensures that only those conclusions that are built on a reliable empirical foundation and comply with basic logical rigor will reach the subsequent, higher-level stages of the audit.

Tier II: Methodological Congruence Audit
The next tier of the audit, implemented by the Methodology Audit Agent, performs a “semantic seam” check—it verifies the integrity of the transition from the analytical arbitration stage to the final narrative synthesis stage. If Echelon I checked the “data → argument” link, Echelon II checks the “argument → conclusion” link. Its task is to ensure that no semantic drift, distortion, or loss of key analytical findings occurred during the stylistic processing and structuring of the final report. This mechanism is an automated implementation of the “audit trail,” which, according to quality research standards, is a key criterion for trustworthiness [Lincoln & Guba, 1985].
The process is broken down into two complementary checks. First, an audit of procedural congruence is conducted. The Agent-Auditor receives both a differential diagnosis report, which records the “winning” hypothesis, and the final qualitative conclusion. Their task is to conduct a detailed semantic comparison, verifying that the final text is an accurate, complete, and undistorted presentation of the hypothesis that won in the competitive comparison. The agent's prompt contains a strict algorithm that requires identifying key statements, nuances, and caveats in the “winning” hypothesis and verifying that they are fully and accurately reflected in the final text.
Second, an audit of theoretical congruence is performed. The agent compares the statements in the final conclusion with the methodological passport of the construct. Its task is to verify that the interpretations given in the conclusion do not go beyond the accepted theoretical model on which the measuring instrument is based. This step is a direct implementation of the construct validity check [Cronbach & Meehl, 1955] at the final stage. It ensures that the system measures and describes precisely the construct that was stated, rather than some kind of “folk” or intuitive psychology, preventing “non-theoretical” speculation.
The microarchitecture of the prompt for this stage, as for the previous one, is focused on procedural rigor. It actively uses Rubric-Based Evaluation and Algorithmic Instruction techniques, forcing the LLM to work in the mode of a strict scientific editor who checks not grammar, but the consistency of conclusions with evidence and theory. This “semantic gateway” ensures that the engineering complexity of the previous stages will not be devalued at the final stage due to carelessness or “creative” deviations when writing the report.

Tier III: Quantitative meta-audit and objectification of reliability
The third echelon of the audit performs a meta-analytical and integrating function. It translates a series of qualitative, expert judgments made at the previous echelons into a single, objectified quantitative metric - the Confidence Score. This process, implemented by a specialized Calculator Agent, is key to ensuring the transparency and comparability of reliability assessments. Its task is not to trust the “Researcher's” self-assessment, but to perform an independent, deterministic recalculation based on a formalized protocol.
This approach is based on the methodology of creating composite indices, where a weighted combination of several heterogeneous indicators is used to obtain a robust assessment [OECD, 2008]. The process begins with the aggregation and normalization of audit findings. The Agent Calculator uses Data Extraction techniques to extract qualitative assessments (“Strong,” “Acceptable,” “Weak”) for all criteria from previous auditors' reports and convert them into numerical values.
Next, the agent applies a strict, predefined weighting formula, implementing the Algorithmic Instruction technique. The prompt is designed to completely eliminate the probabilistic component, turning LLM into a reliable calculator. The formula aggregates four key factors, each of which reflects its own aspect of epistemic validity: completeness of the evidence base (empirical adequacy), structural integrity of the profile (internal coherence), resistance to criticism (compliance with the falsifiability criterion), and diagnostic complexity (explanatory power).
Finally, the agent compares its independently calculated assessment with the initial self-assessment of the “Researcher” and, using Template-Based Generation, generates a detailed textual justification that “reveals” the logic of the calculation. This level is the point of integration and objectification of the entire audit process. It provides accountable reliability, as it does not simply declare quality, but demonstrates how exactly its quantitative assessment was obtained.

Tier IV: Final arbitration and flow management
The final tier of the audit performs a purely executive, rather than analytical, function. This stage, implemented by the Agent-Arbitrator, is the decision-making point in the entire verification pipeline. Having collected all the qualitative and quantitative audit findings from the previous echelons, he, like a judge, delivers a final, binding verdict and, if necessary, forms an “executive list” — a package with instructions for further work. Its key task is to transform a complex, multi-factor audit report into a simple, binary, machine-readable control signal for the main system orchestrator.
This mechanism is the implementation of the “control layer” in hierarchical systems, which is separate from the analytical layers [Mesarović, Macko, & Takahara, 1970]. The Agent-Arbitrator prompt is an executable specification of a deterministic business process. It uses Rule-Based Logic, implementing a decision tree “sewn” into its instructions. The logic of this tree determines the final verdict (“Approved” or “Revision_Required”) based on a combination of all audit assessments received. For example, the verdict ‘Revision_Required’ is given if any of the quality assessments was “Weak” or if the discrepancy between the self-assessment and the independent reliability assessment exceeds a specified threshold.
If revision is required, the agent performs a second task: aggregating and structuring feedback. Using Data Extraction and Template-Based Generation techniques, it does not generate new text, but literally collects all recommendations from previous auditor reports and packages them into a single, structured JSON object. This “package for refinement” is a self-contained artifact that the orchestrator can directly pass to the ‘Researcher’ to start the correction cycle.
This final “control gateway” is the ultimate example of LLM instrumentalization. It ensures that a simple, standardized, and unambiguous control signal is sent to the external system from a complex, multifaceted audit process, ensuring maximum reliability and predictability of interaction between system components.

“Prompt Communicator”: Microarchitecture for Ethical and Didactic Adaptation
If the “Auditor” ensures the reliability of knowledge, then the “Communicator” archetype is responsible for its value and safety for the end user. Its functional purpose is the engineering of didactic and ethical communication, which is a direct architectural response to the risks associated with LLM's lack of empathy and social understanding. It performs the task of “translating” and “packaging” verified expert knowledge into end products, implementing the principle of role orientation. Prompts of this type are stylistically and ethically charged, focusing on tone management, simplicity of presentation, and the psychological impact of the text.
The task of presenting knowledge, like the task of auditing, is decomposed into a complex, fault-tolerant, multi-stage process implemented in the Simplifier pipeline. This process begins with structural validation of the incoming report to ensure fault tolerance. This is followed by iterative stylistic adaptation, where agents sequentially rewrite each section, using the output of the previous step as a stylistic “tuning fork” (Context-driven Stylistic Consistency technique) to ensure global consistency of tone and style throughout the document. In parallel, a sub-pipeline for creating supporting materials is launched, where lexicographer agents form a dynamic glossary, identifying complex terms and generating simple definitions for them. Finally, at the final assembly stage, specialized synthesizer agents create an adapted introduction and conclusion, after which the assembler agent combines all components into a single, coherent Adapted Report.

Sub-pipeline I: Structural validation as a fault-tolerance mechanism
The first step in the Communicator pipeline is not creative adaptation, but rigorous engineering verification. This sub-pipeline, implemented by the Structure Auditor Agent, performs the function of input quality control. Its task is to receive the Professional Report at the input and compare its structure with the reference “report plan” stored in the configuration. The agent checks whether all the planned sections are present in the text and whether they contain any system “placeholders” for errors that occurred at previous stages.
This seemingly technical step has fundamental methodological significance. It is the implementation of the “Fail-Fast” principle, which is one of the best practices in designing reliable systems [Nygard, 2018]. When the system detects an irreparable error at the input (a structurally damaged report), it immediately adapts to it instead of continuing processing in a known incorrect state, which could lead to a cascading failure. Thus, this mechanism ensures the resilience of the entire subsequent complex and resource-intensive adaptation pipeline. Instead of “crashing” in the middle of the process when encountering a missing section, the system receives an accurate “roadmap” (validation_manifest) at the earliest stage, which determines which sections are valid and subject to further processing.
The microarchitecture of the prompt for this agent is a classic example of a “Prompt Auditor.” It is as deterministic and procedural as possible. The prompt contains Rule-Based Logic, which instructs the agent to perform a simple comparison of two lists, and uses Strict I-O Formatting to generate a machine-readable validation report. This mechanism ensures that subsequent, more “creative” adapter agents will only work with high-quality and structurally complete “raw materials,” which is a prerequisite for their reliable and predictable operation.

Sub-pipeline II: Iterative stylistic adaptation and consistency assurance
At the core of the communication adaptation process is an iterative sub-pipeline that sequentially rewrites the text of the Professional Report section by section. This process is implemented by two types of Agent-Adapters and is designed to solve one of the most difficult tasks in generating long texts: ensuring global stylistic coherence.
The process begins with the Initializer Agent, which takes the first valid section of the report and performs its initial, “deep” adaptation. It converts the expert text into a semantically equivalent text that is stylistically and tonally appropriate for the end user. Its prompt is the most methodologically and ethically loaded in the entire Communicator pipeline, as it sets the “gold standard” of style for the entire subsequent document.
Then the Iterative Adapter Agent enters the cycle. For each subsequent section, it receives not only a new fragment of professional text, but also the complete, already adapted text of all previous sections. This mechanism is the implementation of a technique that can be called “context-driven stylistic consistency.” The already adapted text serves as a “stylistic tuning fork” or a dynamic few-shot example. This approach is grounded in the psycholinguistic theory of priming, which shows that the processing of one stimulus (in this case, the already adapted text) influences the processing of the subsequent stimulus, making the model's stylistic choices more consistent.
This iterative, context-enriched approach is a key methodological innovation that overcomes the tendency of LLMs to “drift stylistically” in long generations. It is grounded in discursive linguistics, which views text not as a set of sentences, but as a holistic, coherent structure where each subsequent element is linked to the previous ones [van Dijk, 1997]. The architecture of this sub-pipeline emulates the work process of an experienced human editor who constantly rereads what has already been written to maintain stylistic unity. This ensures that the final Adapted Report will be perceived not as a “patchwork quilt” of processed fragments, but as a coherent, organic document written in a “single voice.”

Sub-pipeline III: Dynamic creation of auxiliary teaching materials
To increase the educational value and comprehensibility of the Adapted Report, the system implements a parallel sub-pipeline for creating a dynamic glossary. This process is an example of how the system can generate supplementary teaching materials directly related to the main content. The process is broken down into two specialized, sequential tasks.
In the first step, the Lexicographer Agent performs an intelligent scan of the entire adapted text of the report. Its task is not simply to find difficult words, but to identify highly specialized psychological terms that may be incomprehensible to a non-specialist. This agent's prompt implements the Data Extraction technique with semantic filtering: it contains instructions to distinguish terms relevant to the glossary (e.g., “coping strategies,” “emotional regulation”) from commonly used psychological words (“emotions,” “stress”) and from the names of the constructs themselves, which are already explained in the main text. This allows the glossary to be concise and focused.
In the second step, Agent-Glossator receives a filtered list of terms as input. Its task is to generate a simple, clear, and methodologically correct definition for each term. The prompt for this agent is an example of a Task Specification with strict stylistic constraints. This two-step approach is grounded in the principles of instructional design, in particular the concept of “scaffolding” proposed by Jerome Bruner and his colleagues [Wood, Bruner, & Ross, 1976]. The glossary acts as such scaffolding, providing the user with the necessary support to understand complex material and facilitating the assimilation of new concepts, which is a key element in the zone of proximal development, according to L.S. Vygotsky's theory [Vygotsky, 2005]. The dynamic nature of this process ensures that the glossary will always be relevant and specific to the text that was generated for a particular user, which is a significant advantage over static, pre-compiled dictionaries.

Sub-pipeline IV: Final synthesis and assembly
The final stage in the Communicator pipeline is the assembly of all pre-processed and generated components into a single, coherent Adapted Report. This seemingly technical process is also decomposed into semantically complex and simple tasks to ensure maximum quality and reliability.
The process begins with the work of two parallel Synthesis Agents, which create the adapted Introduction and Conclusion. These agents perform a complex intellectual task. Unlike iterative adapters, which work with local sections, these agents receive the full context of the entire already adapted body of the report as input.
•	The Introduction Synthesis Agent uses this context to create a conceptual and emotional “framework” that manages user expectations, explains the purpose of the report (as an “analytical mirror”), and subtly announces the key themes identified in the analysis, making the introduction personalized.
•	The Conclusion Agent-Synthesizer performs the final meta-synthesis, “translating” complex integrative conclusions from the Professional Report into the language of usefulness and self-reflection, formulating “growth points” and a motivating conclusion.
Once all four components (Introduction, Body, Conclusion, and optional Glossary) are ready, the final Agent-Assembler comes into play. Its function is purely technical and deterministic. It does not generate new meaning, but performs a concatenation operation using the Template-Based Generation technique.
This decomposition into “smart” synthesizers and a “dumb” assembler is an implementation of the Single Responsibility Principle [Martin, 2017]. It is grounded in engineering practice, where complex, intellectual tasks (synthesis) are separated from simple, mechanical ones (assembly). This allows the prompts of the synthesizers to remain focused on their creative task, while the assembler's prompt remains as simple and reliable as possible. This final sub-pipeline ensures that the final Adapted Report will not only be semantically and stylistically coherent, but also structurally flawless.

Bibliography:
1.	Chamberlin, T. C. (1890). The method of multiple working hypotheses. Science, ns-15(366), 92–96. https://doi.org/10.1126/science.ns-15.366.92
2.	Craik, F. I. M., & Lockhart, R. S. (1972). Levels of processing. Journal of Verbal Learning and Verbal Behavior, 11(6), 671–684. https://doi.org/10.1016/S0022-5371(72)80001-X
3.	Creswell, J. W., & Plano Clark, V. L. (2017). Designing and conducting mixed methods research (3rd ed.). SAGE.
4.	Cronbach, L. J., & Meehl, P. E. (1955). Construct validity in psychological tests. Psychological Bulletin, 52(4), 281–302. https://doi.org/10.1037/h0040957
5.	Flavell, J. H. (1979). Metacognition and cognitive monitoring. American Psychologist, 34(10), 906–911. https://doi.org/10.1037/0003-066X.34.10.906
6.	Lincoln, Y. S., & Guba, E. G. (1985). Naturalistic inquiry. SAGE.
7.	Martin, R. C. (2017). Clean architecture: A craftsman’s guide to software structure and design. Pearson. ISBN 9780134494166.
8.	Merton, R. K. (1973). The normative structure of science. In The sociology of science: Theoretical and empirical investigations. University of Chicago Press.
9.	Mesarovic, M. D., Macko, D., & Takahara, Y. (1970). Theory of hierarchical, multilevel systems. Academic Press.
10.	Nygard, M. T. (2018). Release It! (2nd ed.). Pragmatic Bookshelf.
11.	OECD, & JRC. (2008). Handbook on constructing composite indicators. OECD Publishing. https://doi.org/10.1787/9789264043466-en
12.	Popper, K. (2002). The logic of scientific discovery (Routledge Classics ed.). Routledge. (Original work published 1959).
13.	Reichenbach, H. (1938). Experience and prediction. University of Chicago Press.
14.	Toulmin, S. E. (1958). The uses of argument. Cambridge University Press. https://doi.org/10.1017/CBO9780511840005 (Updated ed. 2003).
15.	van Dijk, T. A. (Ed.). (1997). Discourse as social interaction (Vol. 2). SAGE.
16.	van Dijk, T. A. (Ed.). (1997). Discourse as structure and process (Vol. 1). SAGE.
17.	Wood, D., Bruner, J. S., & Ross, G. (1976). The role of tutoring in problem solving. Journal of Child Psychology and Psychiatry, 17(2), 89–100. https://doi.org/10.1111/j.1469-7610.1976.tb00381.x
18.	Выготский, Л. С. (2005). Психология развития человека. Москва: Смысл; Эксмо. ISBN 5-699-13728-9.

